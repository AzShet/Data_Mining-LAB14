{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c802889",
   "metadata": {},
   "source": [
    "# Session 14: Assembly techniques (with more accuracy)\n",
    "Made by:\n",
    "\n",
    "**- Ruelas Flores, César Diego**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c7b61b",
   "metadata": {},
   "source": [
    "This is a new notebook, 'LAB14-RUELAS-robust.ipynb'. We will focus on three pillars to maximize performance:\n",
    "\n",
    "Advanced Feature Engineering: We will extract valuable information from the date column and create new features to give the model greater predictive power.\n",
    "State-of-the-art Models: We will incorporate XGBoost and LightGBM, the industry-standard models for tabular data.\n",
    "Robust Optimization and Evaluation: We will use RandomizedSearchCV with cross-validation to efficiently find the best hyperparameters and obtain highly reliable performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5985f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install xgboost lightgbm catboost -q (esto va a demorar como unos 5 minutos o menos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83246d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-19 17:40:49,072 - root - INFO - Entorno ROBUSTO configurado y librerías importadas.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuración General del Entorno ---\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# --- Modelos Avanzados ---\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# --- Configuración Centralizada del Logging ---\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    stream=sys.stdout\n",
    ")\n",
    "\n",
    "logging.info(\"Entorno ROBUSTO configurado y librerías importadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5876fc",
   "metadata": {},
   "source": [
    "## 1. VARIABLES GLOBALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef47a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-19 17:40:49,085 - root - INFO - Variables globales definidas.\n"
     ]
    }
   ],
   "source": [
    "TARGET_COLUMN = 'actual_productivity'\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "# Número de iteraciones para la búsqueda aleatoria de hiperparámetros\n",
    "N_ITER_SEARCH = 20\n",
    "\n",
    "logging.info(\"Variables globales definidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d9e87",
   "metadata": {},
   "source": [
    "## 2. FUNCIONES (../src/utils_robust.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b857adc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/utils_robust.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/utils_robust.py\n",
    "import logging\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "# --- IMPORTACIÓN AÑADIDA ---\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Obtenemos el logger para este módulo\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_and_engineer_features() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carga los datos y realiza ingeniería de características avanzada.\n",
    "    \"\"\"\n",
    "    logger.info(\"Iniciando carga de datos e ingeniería de características...\")\n",
    "    try:\n",
    "        garment_prod = fetch_ucirepo(id=597)\n",
    "        df = pd.concat([garment_prod.data.features, garment_prod.data.targets], axis=1)\n",
    "        \n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df['month'] = df['date'].dt.month\n",
    "        df['week_of_year'] = df['date'].dt.isocalendar().week.astype(int)\n",
    "        df['day_of_week'] = df['date'].dt.dayofweek\n",
    "        df = df.drop(columns=['date'])\n",
    "        logger.info(\"Características de tiempo creadas desde la columna 'date'.\")\n",
    "\n",
    "        df['incentive_per_target'] = df['incentive'] / (df['targeted_productivity'] + 1e-6)\n",
    "        df['smv_per_worker'] = df['smv'] / (df['no_of_workers'] + 1e-6)\n",
    "        logger.info(\"Características de ratio creadas.\")\n",
    "\n",
    "        for col in df.columns[df.isnull().any()]:\n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "        logger.info(\"Valores nulos imputados con la mediana.\")\n",
    "                \n",
    "        logger.info(f\"Proceso finalizado. Dimensiones del DataFrame: {df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error durante la carga e ingeniería de características: {e}\")\n",
    "        raise\n",
    "\n",
    "def find_best_model(X_train: pd.DataFrame, y_train: pd.Series, n_iter: int, cv: int, random_state: int) -> Tuple[object, Dict]:\n",
    "    \"\"\"\n",
    "    Busca el mejor modelo y sus hiperparámetros usando RandomizedSearchCV.\n",
    "    \"\"\"\n",
    "    logger.info(\"Iniciando la búsqueda del mejor modelo robusto...\")\n",
    "\n",
    "    numeric_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # --- CAMBIO EN EL PREPROCESADOR ---\n",
    "    # Se reemplaza 'passthrough' por OneHotEncoder para las variables categóricas.\n",
    "    # handle_unknown='ignore' evita errores durante la validación cruzada si una categoría\n",
    "    # no está presente en algún pliegue (fold).\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    search_spaces = {\n",
    "        'RandomForest': (\n",
    "            RandomForestRegressor(random_state=random_state),\n",
    "            {\n",
    "                'model__n_estimators': [100, 200, 300],\n",
    "                'model__max_depth': [10, 20, 30],\n",
    "                'model__min_samples_leaf': [1, 2, 4],\n",
    "                'model__max_features': ['sqrt', 'log2'],\n",
    "            }\n",
    "        ),\n",
    "        'XGBoost': (\n",
    "            XGBRegressor(random_state=random_state, objective='reg:squarederror'),\n",
    "            {\n",
    "                'model__n_estimators': [100, 200, 500],\n",
    "                'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "                'model__max_depth': [3, 5, 7],\n",
    "                'model__subsample': [0.7, 0.8, 0.9],\n",
    "                'model__colsample_bytree': [0.7, 0.8, 0.9],\n",
    "            }\n",
    "        ),\n",
    "        'LightGBM': (\n",
    "            LGBMRegressor(random_state=random_state),\n",
    "            {\n",
    "                'model__n_estimators': [100, 200, 500],\n",
    "                'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "                'model__num_leaves': [20, 31, 40],\n",
    "                'model__max_depth': [-1, 10, 20],\n",
    "                'model__subsample': [0.7, 0.8, 0.9],\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_score = -np.inf\n",
    "    results = {}\n",
    "\n",
    "    for name, (model, params) in search_spaces.items():\n",
    "        logger.info(f\"--- Optimizando {name} ---\")\n",
    "        \n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "\n",
    "        search = RandomizedSearchCV(\n",
    "            pipeline, params, n_iter=n_iter, scoring='r2', n_jobs=-1,\n",
    "            cv=cv, verbose=1, random_state=random_state\n",
    "        )\n",
    "        search.fit(X_train, y_train)\n",
    "\n",
    "        logger.info(f\"Mejor R2 score para {name} (CV): {search.best_score_:.4f}\")\n",
    "        logger.info(f\"Mejores parámetros: {search.best_params_}\")\n",
    "\n",
    "        results[name] = {'best_score': search.best_score_, 'best_params': search.best_params_}\n",
    "\n",
    "        if search.best_score_ > best_score:\n",
    "            best_score = search.best_score_\n",
    "            best_model = search.best_estimator_\n",
    "            results['best_overall_model'] = name\n",
    "    \n",
    "    logger.info(f\"Búsqueda finalizada. Mejor modelo global: {results['best_overall_model']}\")\n",
    "    return best_model, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee617024",
   "metadata": {},
   "source": [
    "## 3. IMPLEMENTACIÓN PRINCIPAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "622e8c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-19 17:40:49,134 - root - INFO - Módulo 'utils_robust' importado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuración de la ruta del proyecto ---\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.insert(0, project_root)\n",
    "    # Usamos un alias para mantener el código limpio\n",
    "    from src import utils_robust as utils\n",
    "    logging.info(\"Módulo 'utils_robust' importado exitosamente.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error en la configuración inicial del path: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95224fe",
   "metadata": {},
   "source": [
    "### 3.1 Parte A: Preprocesamiento con Ingeniería de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfade76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-19 17:40:49,147 - root - INFO - --- [PARTE A] Iniciando preprocesamiento robusto ---\n",
      "2025-06-19 17:40:49,149 - src.utils_robust - INFO - Iniciando carga de datos e ingeniería de características...\n",
      "2025-06-19 17:40:50,987 - src.utils_robust - INFO - Características de tiempo creadas desde la columna 'date'.\n",
      "2025-06-19 17:40:50,990 - src.utils_robust - INFO - Características de ratio creadas.\n",
      "2025-06-19 17:40:50,993 - src.utils_robust - INFO - Valores nulos imputados con la mediana.\n",
      "2025-06-19 17:40:50,994 - src.utils_robust - INFO - Proceso finalizado. Dimensiones del DataFrame: (1197, 19)\n",
      "2025-06-19 17:40:50,995 - root - INFO - --- [PARTE A] Preprocesamiento robusto finalizado ---\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"--- [PARTE A] Iniciando preprocesamiento robusto ---\")\n",
    "# La función ahora se encarga de la carga, limpieza e ing. de características.\n",
    "df_engineered = utils.load_and_engineer_features()\n",
    "logging.info(\"--- [PARTE A] Preprocesamiento robusto finalizado ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a330e13",
   "metadata": {},
   "source": [
    "### 3.2. Parte B: Separación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b107d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-19 17:40:51,006 - root - INFO - --- [PARTE B] Iniciando separación de datos ---\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"--- [PARTE B] Iniciando separación de datos ---\")\n",
    "# Separar características (X) y objetivo (y) antes de cualquier transformación\n",
    "X = df_engineered.drop(columns=TARGET_COLUMN)\n",
    "y = df_engineered[TARGET_COLUMN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f230508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-19 17:40:51,029 - root - INFO - Datos divididos: 957 para entrenamiento, 240 para prueba.\n",
      "2025-06-19 17:40:51,031 - root - INFO - --- [PARTE B] Separación de datos finalizada ---\n"
     ]
    }
   ],
   "source": [
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "logging.info(f\"Datos divididos: {len(X_train)} para entrenamiento, {len(X_test)} para prueba.\")\n",
    "logging.info(\"--- [PARTE B] Separación de datos finalizada ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d95dd1",
   "metadata": {},
   "source": [
    "### 3.3. Parte C: Búsqueda, Entrenamiento y Evaluación del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae28eca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-19 17:40:51,045 - root - INFO - --- [PARTE C] Iniciando búsqueda y entrenamiento del mejor modelo ---\n",
      "2025-06-19 17:40:51,047 - src.utils_robust - INFO - Iniciando la búsqueda del mejor modelo robusto...\n",
      "2025-06-19 17:40:51,051 - src.utils_robust - INFO - --- Optimizando RandomForest ---\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "2025-06-19 17:41:06,845 - src.utils_robust - INFO - Mejor R2 score para RandomForest (CV): 0.4900\n",
      "2025-06-19 17:41:06,847 - src.utils_robust - INFO - Mejores parámetros: {'model__n_estimators': 300, 'model__min_samples_leaf': 2, 'model__max_features': 'sqrt', 'model__max_depth': 10}\n",
      "2025-06-19 17:41:06,847 - src.utils_robust - INFO - --- Optimizando XGBoost ---\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "2025-06-19 17:41:13,214 - src.utils_robust - INFO - Mejor R2 score para XGBoost (CV): 0.4993\n",
      "2025-06-19 17:41:13,216 - src.utils_robust - INFO - Mejores parámetros: {'model__subsample': 0.9, 'model__n_estimators': 200, 'model__max_depth': 3, 'model__learning_rate': 0.05, 'model__colsample_bytree': 0.8}\n",
      "2025-06-19 17:41:13,218 - src.utils_robust - INFO - --- Optimizando LightGBM ---\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 679\n",
      "[LightGBM] [Info] Number of data points in the train set: 957, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 0.732472\n",
      "2025-06-19 17:41:40,082 - src.utils_robust - INFO - Mejor R2 score para LightGBM (CV): 0.4605\n",
      "2025-06-19 17:41:40,083 - src.utils_robust - INFO - Mejores parámetros: {'model__subsample': 0.8, 'model__num_leaves': 20, 'model__n_estimators': 100, 'model__max_depth': -1, 'model__learning_rate': 0.05}\n",
      "2025-06-19 17:41:40,084 - src.utils_robust - INFO - Búsqueda finalizada. Mejor modelo global: XGBoost\n",
      "2025-06-19 17:41:40,085 - root - INFO - --- [PARTE C] Búsqueda y entrenamiento finalizados ---\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"--- [PARTE C] Iniciando búsqueda y entrenamiento del mejor modelo ---\")\n",
    "# La función ahora encuentra y entrena el mejor modelo usando CV y búsqueda de hiperparámetros.\n",
    "# El escalado y la codificación se realizan DENTRO del pipeline en la función.\n",
    "best_model_pipeline, training_results = utils.find_best_model(\n",
    "    X_train, y_train, n_iter=N_ITER_SEARCH, cv=5, random_state=RANDOM_STATE\n",
    ")\n",
    "logging.info(\"--- [PARTE C] Búsqueda y entrenamiento finalizados ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a398aa",
   "metadata": {},
   "source": [
    "### 3.4. Evaluación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed0d77",
   "metadata": {},
   "source": [
    "#### 3.4.1. Evaluación Final del Mejor Modelo en el Conjunto de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c8f36d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-19 17:41:40,098 - root - INFO - --- EVALUACIÓN FINAL SOBRE DATOS DE PRUEBA (TEST SET) ---\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"--- EVALUACIÓN FINAL SOBRE DATOS DE PRUEBA (TEST SET) ---\")\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e925aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar el pipeline del mejor modelo para predecir en el conjunto de prueba\n",
    "y_pred_final = best_model_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0350f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas finales\n",
    "final_r2 = r2_score(y_test, y_pred_final)\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, y_pred_final))\n",
    "final_mae = mean_absolute_error(y_test, y_pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346f797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "2025-06-19 17:41:40,162 - root - INFO - Resultados de la Búsqueda y Optimización (sobre datos de entrenamiento con CV):\n",
      "2025-06-19 17:41:40,164 - root - INFO -   - RandomForest: Mejor R2 (CV) = 0.4900\n",
      "2025-06-19 17:41:40,165 - root - INFO -   - XGBoost: Mejor R2 (CV) = 0.4993\n",
      "2025-06-19 17:41:40,166 - root - INFO -   - LightGBM: Mejor R2 (CV) = 0.4605\n",
      "\n",
      "==================================================\n",
      "2025-06-19 17:41:40,168 - root - INFO - Rendimiento del Mejor Modelo ('XGBoost') en el Conjunto de Prueba (Test Set):\n",
      "2025-06-19 17:41:40,169 - root - INFO -   - R2 Score Final: 0.4819\n",
      "2025-06-19 17:41:40,170 - root - INFO -   - RMSE Final:   0.1173\n",
      "2025-06-19 17:41:40,172 - root - INFO -   - MAE Final:    0.0768\n",
      "==================================================\n",
      "2025-06-19 17:41:40,173 - root - INFO - \n",
      "--- CONCLUSIÓN ROBUSTA ---\n",
      "Tras una exhaustiva ingeniería de características y optimización de hiperparámetros,\n",
      "el mejor modelo encontrado fue 'XGBoost'.\n",
      "En el conjunto de datos de prueba, que el modelo nunca había visto, se obtuvo un\n",
      "R² Score de 0.4819. Este resultado representa el rendimiento real y\n",
      "generalizable del modelo final.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimir resultados del entrenamiento y la evaluación final\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "logging.info(\"Resultados de la Búsqueda y Optimización (sobre datos de entrenamiento con CV):\")\n",
    "for model_name, result in training_results.items():\n",
    "    if model_name != 'best_overall_model':\n",
    "        logging.info(f\"  - {model_name}: Mejor R2 (CV) = {result['best_score']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "logging.info(f\"Rendimiento del Mejor Modelo ('{training_results['best_overall_model']}') en el Conjunto de Prueba (Test Set):\")\n",
    "logging.info(f\"  - R2 Score Final: {final_r2:.4f}\")\n",
    "logging.info(f\"  - RMSE Final:   {final_rmse:.4f}\")\n",
    "logging.info(f\"  - MAE Final:    {final_mae:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "logging.info(f\"\"\"\n",
    "--- CONCLUSIÓN ROBUSTA ---\n",
    "Tras una exhaustiva ingeniería de características y optimización de hiperparámetros,\n",
    "el mejor modelo encontrado fue '{training_results['best_overall_model']}'.\n",
    "En el conjunto de datos de prueba, que el modelo nunca había visto, se obtuvo un\n",
    "R² Score de {final_r2:.4f}. Este resultado representa el rendimiento real y\n",
    "generalizable del modelo final.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f5a837",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0673a0",
   "metadata": {},
   "source": [
    "Aunque a primera vista el R² de 0.4973 del modelo 'Bagging' (de nuestro LAB14-RUELAS.ipynb) parece más alto, la clave para determinar cuál es \"mejor\" no está solo en el número final, sino en la **confianza, robustez y fiabilidad** del proceso que lo generó.\n",
    "\n",
    "Aquí la comparación detallada:\n",
    "\n",
    "| Característica | Resultado 1 (Simple) | Resultado 2 (Robusto) | Ganador |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Mejor Modelo** | Bagging | XGBoost | **XGBoost** |\n",
    "| **R² Score Final** | 0.4973 (en Test Set) | 0.4819 (en Test Set) | (Número más alto: Bagging) |\n",
    "| **RMSE Final** | 0.1155 (en Test Set) | 0.1173 (en Test Set) | (Error más bajo: Bagging) |\n",
    "| **Metodología** | Evaluación simple (un solo split) | Búsqueda exhaustiva, Ingeniería de Características y Validación Cruzada (CV) | **XGBoost** |\n",
    "| **Confianza** | Baja (podría ser un resultado por \"suerte\") | Alta (rendimiento probado y generalizable) | **XGBoost** |\n",
    "\n",
    "#### Justificación Detallada\n",
    "\n",
    "1.  **Fiabilidad del Proceso:** El resultado del modelo Bagging proviene de una única división de datos. Esto significa que el R² de 0.4973 podría ser producto del azar; simplemente la división de datos de entrenamiento y prueba resultó ser favorable para ese modelo en particular. No tenemos garantía de que se comporte igual con una división de datos diferente.\n",
    "\n",
    "2.  **El Poder de la Validación Cruzada (CV):** El proceso del modelo XGBoost es mucho más riguroso. Antes de llegar al resultado final, se realizó una \"Búsqueda y Optimización\" usando validación cruzada. El resultado de `XGBoost: Mejor R2 (CV) = 0.4993` nos dice que, en promedio, a través de múltiples divisiones de los datos de entrenamiento, el modelo tuvo un excelente rendimiento.\n",
    "\n",
    "3.  **Confirmación con el Test Set:** El paso final fue tomar el mejor modelo de la fase de CV (XGBoost) y evaluarlo en el conjunto de prueba, que nunca antes había visto. El resultado fue un `R2 Score Final: 0.4819`. Que este número sea muy cercano al resultado de la validación cruzada (0.4993 vs 0.4819) es una **excelente señal**. Confirma que el modelo no está sobreajustado y que su rendimiento es estable y predecible.\n",
    "\n",
    "**En resumen:**\n",
    "\n",
    "El resultado del modelo **Bagging** es como una buena foto instantánea: podría ser favorecedora, pero no cuenta toda la historia.\n",
    "\n",
    "El resultado del modelo **XGBoost** es como un video bien grabado: nos muestra un rendimiento consistente y fiable a lo largo del tiempo. Aunque el número final sea una fracción más bajo, es un resultado en el que **puedes confiar** para hacer predicciones sobre datos futuros. En cualquier proyecto profesional de ciencia de datos, la confianza y la generalización del modelo son mucho más valiosas que un número ligeramente más alto obtenido de un proceso menos riguroso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292fa7b4",
   "metadata": {},
   "source": [
    "## 4. TESTING (../tests/test_utils_robust.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be4c24c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../tests/test_utils_robust.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../tests/test_utils_robust.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src import utils_robust\n",
    "\n",
    "def test_load_and_engineer_features():\n",
    "    \"\"\"\n",
    "    Prueba que la carga de datos y la ingeniería de características funcionen.\n",
    "    \"\"\"\n",
    "    df = utils_robust.load_and_engineer_features()\n",
    "    \n",
    "    # 1. Comprobar que es un DataFrame de pandas\n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "    \n",
    "    # 2. Comprobar que 'date' fue eliminada y las nuevas columnas de tiempo existen\n",
    "    assert 'date' not in df.columns\n",
    "    assert 'month' in df.columns\n",
    "    assert 'week_of_year' in df.columns\n",
    "    assert 'day_of_week' in df.columns\n",
    "    \n",
    "    # 3. Comprobar que las nuevas características de ratio existen\n",
    "    assert 'incentive_per_target' in df.columns\n",
    "    assert 'smv_per_worker' in df.columns\n",
    "    \n",
    "    # 4. Comprobar que no hay valores nulos\n",
    "    assert df.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd189a7",
   "metadata": {},
   "source": [
    "## 5. EJECUCIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f4571d",
   "metadata": {},
   "source": [
    "# 5.1. Ejecución de Pruebas Unitarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fc41bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python del Kernel Jupyter: c:\\Users\\AzShet\\Documents\\Jupyter_LAB\\jupyter_projects\\5to_ciclo\\DataMining\\lab14\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Esta es la ruta del Python que usa tu KERNEL (debería estar dentro de .venv)\n",
    "print(f\"Python del Kernel Jupyter: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c11ed48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.13.3, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\AzShet\\Documents\\Jupyter_LAB\\jupyter_projects\\5to_ciclo\\DataMining\\lab14\\.venv\\Scripts\\python.exe\n",
      "rootdir: c:\\Users\\AzShet\\Documents\\Jupyter_LAB\\jupyter_projects\\5to_ciclo\\DataMining\\lab14\\Data_Mining-LAB14\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "..\\tests\\test_utils_robust.py::test_load_and_engineer_features \u001b[32mPASSED\u001b[0m\u001b[32m    [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 4.61s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest ../tests/test_utils_robust.py -v -p no:cacheprovider"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
